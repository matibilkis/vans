{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write a simplifier a la Luckasz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy\n",
    "import cirq\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, n_qubits=3, qlr=0.01, qepochs=100,verbose=0, g=1, J=0):\n",
    "\n",
    "        \"\"\"\"solver with n**2 possible actions: n(n-1) CNOTS + n 1-qubit unitary\"\"\"\n",
    "        self.n_qubits = n_qubits\n",
    "        self.qubits = cirq.GridQubit.rect(1, n_qubits)\n",
    "        self.lower_bound_Eg = -2*self.n_qubits\n",
    "        \n",
    "        self.qlr = qlr\n",
    "        self.qepochs=qepochs\n",
    "        self.verbose=verbose\n",
    "\n",
    "\n",
    "        self.indexed_cnots = {}\n",
    "        self.cnots_index = {}\n",
    "        count = 0\n",
    "        for control in range(self.n_qubits):\n",
    "            for target in range(self.n_qubits):\n",
    "                if control != target:\n",
    "                    self.indexed_cnots[str(count)] = [control, target]\n",
    "                    self.cnots_index[str([control,target])] = count\n",
    "                    count += 1\n",
    "        self.number_of_cnots = len(self.indexed_cnots)\n",
    "        \n",
    "        self.final_params = []\n",
    "        self.parametrized_unitary = [cirq.rz, cirq.rx, cirq.rz]\n",
    "        \n",
    "        self.observable=self.ising_obs(g=g, J=J)\n",
    "        self.resolver = {}\n",
    "        self.lowest_energy_found = -.1\n",
    "        \n",
    "    def ising_obs(self, g=1, J=0):\n",
    "        # g \\sum_i Z_i - J \\sum_{i} X_i X_{i+1}\n",
    "        observable = [float(g)*cirq.Z.on(q) for q in self.qubits] \n",
    "        for q in range(len(self.qubits)):\n",
    "            observable.append(float(J)*cirq.X.on(self.qubits[q])*cirq.X.on(self.qubits[(q+1)%len(self.qubits)]))\n",
    "        self.ground_energy = -g*np.sum(np.sqrt([1+(J/4*g)**2 - (np.cos(q)*(J/2*g)) for q in range(self.n_qubits)]))\n",
    "        return observable\n",
    "        \n",
    "    def index_meaning(self,index):\n",
    "        if index<self.number_of_cnots:\n",
    "            print(\"cnot: \",self.indexed_cnots[str(index)])\n",
    "            return\n",
    "        else:\n",
    "            print(\"1-qubit unitary on: \",(index-self.number_of_cnots)%self.n_qubits)\n",
    "            return\n",
    "\n",
    "    def append_to_circuit(self, ind, circuit, params, new_index=False):\n",
    "        \"\"\"\n",
    "        appends to circuit the index of the gate;\n",
    "        and if one_hot_gate implies a rotation,\n",
    "        appends to params a symbol\n",
    "        \"\"\"\n",
    "        if ind < self.number_of_cnots:\n",
    "            control, target = self.indexed_cnots[str(ind)]\n",
    "            circuit.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "            return circuit, params\n",
    "        else:\n",
    "            qubit = self.qubits[(ind-self.number_of_cnots)%self.n_qubits]\n",
    "            for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                new_param = \"th_\"+str(len(params))\n",
    "                params.append(new_param)\n",
    "                circuit.append(gate(sympy.Symbol(new_param)).on(qubit))\n",
    "            return circuit, params\n",
    "        \n",
    "    def give_circuit(self, lista,one_hot=False):\n",
    "        circuit, symbols = [], []\n",
    "        for k in lista:\n",
    "            circuit, symbols = self.append_to_circuit(k,circuit,symbols)\n",
    "        circuit = cirq.Circuit(circuit)\n",
    "        return circuit, symbols\n",
    "    \n",
    "    \n",
    "    def resolution_2cnots(self, q1, q2):\n",
    "        u1 = self.number_of_cnots + q1\n",
    "        u2 = self.number_of_cnots + q2\n",
    "        cnot = self.cnots_index[str([q1,q2])]\n",
    "        return [cnot, u1, u2, cnot]\n",
    "    \n",
    "    def resolution_1qubit(self, q):\n",
    "        u1 = self.number_of_cnots + q\n",
    "        return [u1]\n",
    "        \n",
    "\n",
    "    def dressed_cnot(self,q1,q2):\n",
    "        u1 = self.number_of_cnots + q1\n",
    "        u2 = self.number_of_cnots + q2\n",
    "        cnot = self.cnots_index[str([q1,q2])]\n",
    "        u3 = self.number_of_cnots + q1\n",
    "        u4 = self.number_of_cnots + q2\n",
    "        return [u1,u2,cnot,u3,u4]\n",
    "    \n",
    "    def dressed_ansatz(self, layers=1):\n",
    "        c=[]\n",
    "        for layer in range(layers):\n",
    "            qubits = list(range(self.n_qubits))\n",
    "            qdeph = qubits[layers:]\n",
    "            for q in qubits[:layers]:\n",
    "                qdeph.append(q)\n",
    "            for ind1, ind2 in zip(qubits,qdeph):\n",
    "                for k in self.dressed_cnot(ind1,ind2):\n",
    "                    c.append(k)\n",
    "        return c\n",
    "\n",
    "\n",
    "    def prepare_circuit_insertion(self,gates_index, block_to_insert, index_insertion):\n",
    "        \"\"\"gates_index is a vector with integer entries, each one describing a gate\n",
    "            block_to_insert is block of unitaries to insert at index insertion\n",
    "        \"\"\"\n",
    "        circuit = cirq.Circuit()\n",
    "        symbols = []\n",
    "        new_symbols = []\n",
    "        new_resolver = {}\n",
    "\n",
    "        for ind, g in enumerate(gates_index):\n",
    "            #### insert new block ####\n",
    "            if ind == insertion_index:\n",
    "                for gate in block_to_insert:\n",
    "                    if gate < self.number_of_cnots:\n",
    "                        control, target = self.indexed_cnots[str(gate)]\n",
    "                        circuit.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "                    else:\n",
    "                        qubit = self.qubits[(gate-self.number_of_cnots)%self.n_qubits]\n",
    "                        for par, gateblack in zip(range(3),self.parametrized_unitary):\n",
    "                            new_symbol = \"New_th_\"+str(len(new_symbols))\n",
    "                            new_symbols.append(new_symbol)\n",
    "                            new_resolver[new_symbol] = np.random.uniform(-.01,.01) #rotation around epsilon... we can do it better afterwards\n",
    "                            circuit.append(gateblack(sympy.Symbol(new_symbol)).on(qubit))\n",
    "            if g < self.number_of_cnots:\n",
    "                control, target = self.indexed_cnots[str(ind)]\n",
    "                circuit.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "            else:\n",
    "                qubit = self.qubits[(ind-self.number_of_cnots)%self.n_qubits]\n",
    "                for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                    new_symbol = \"th_\"+str(len(symbols))\n",
    "                    symbols.append(new_symbol)\n",
    "                    circuit.append(gate(sympy.Symbol(new_symbol)).on(qubit))\n",
    "                    if not new_symbol in self.resolver.keys(): #this is in case it's the first time. Careful when deleting !\n",
    "                        self.resolver[new_symbol] = np.random.uniform(-np.pi, np.pi)\n",
    "\n",
    "        ### add identity for TFQ tocompute correctily expected value####\n",
    "        effective_qubits = list(circuit.all_qubits())\n",
    "        for k in self.qubits:\n",
    "            if k not in effective_qubits:\n",
    "                circuit.append(cirq.I.on(k))\n",
    "        self.new_resolver = new_resolver\n",
    "        variables = [symbols, new_symbols]\n",
    "        return circuit, variables\n",
    "    \n",
    "    \n",
    "    \n",
    "    def TFQ_model(self, symbols):\n",
    "        circuit_input = tf.keras.Input(shape=(), dtype=tf.string)\n",
    "        output = tfq.layers.Expectation()(\n",
    "                circuit_input,\n",
    "                symbol_names=symbols,\n",
    "                operators=tfq.convert_to_tensor([self.observable]),\n",
    "                initializer=tf.keras.initializers.RandomNormal()) #we may change this!!!\n",
    "\n",
    "        model = tf.keras.Model(inputs=circuit_input, outputs=output)\n",
    "        adam = tf.keras.optimizers.Adam(learning_rate=self.qlr)\n",
    "        model.compile(optimizer=adam, loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def initialize_model_insertion(self, variables):\n",
    "        ### initialize model with parameters from previous model (describer by variables[0]) --> values in self.resolver\n",
    "        ###(for the already-optimized ones), and close to identity for the block added, described by variables[1], whose values are in self.new_resolver\n",
    "\n",
    "        symbols, new_symbols = variables\n",
    "        circuit_symbols = []\n",
    "        init_params = []\n",
    "        for j in symbols:\n",
    "            circuit_symbols.append(j)\n",
    "            init_params.append(self.resolver[str(j)])#+ np.random.uniform(-.01,.01)) if you want to perturbate previous parameters..\n",
    "        for k in new_symbols:\n",
    "            circuit_symbols.append(k)\n",
    "            init_params.append(self.new_resolver[str(k)])\n",
    "\n",
    "        model = self.TFQ_model(circuit_symbols)\n",
    "        model.trainable_variables[0].assign(tf.convert_to_tensor(init_params)) #initialize parameters of model (continuous parameters of uniraries)\n",
    "        #with the corresponding values\n",
    "        return model\n",
    "\n",
    "    def run_circuit_from_index(self, gates_index):\n",
    "        \"\"\"\n",
    "        takes as input vector with actions described as integer\n",
    "        and outputsthe energy of that circuit (w.r.t self.observable)\n",
    "        \"\"\"\n",
    "        ### create a vector with the gates on the corresponding qubit(s)\n",
    "        circuit, symbols = self.give_circuit(gates_index)\n",
    "        \n",
    "        ### this is because each qubit should be \"activated\" in TFQ to do the optimization (if the observable has support on this qubit as well and you don't add I then error)\n",
    "        effective_qubits = list(circuit.all_qubits())\n",
    "        for k in self.qubits:\n",
    "            if k not in effective_qubits:\n",
    "                circuit.append(cirq.I.on(k))\n",
    "\n",
    "        tfqcircuit = tfq.convert_to_tensor([circuit])\n",
    "        if len(symbols) == 0:\n",
    "            expval = tfq.layers.Expectation()(\n",
    "                                            tfqcircuit,\n",
    "                                            operators=tfq.convert_to_tensor([self.observable]))\n",
    "            energy = np.float32(np.squeeze(tf.math.reduce_sum(expval, axis=-1, keepdims=True)))\n",
    "            final_params = []\n",
    "            resolver = {\"th_\"+str(ind):var  for ind,var in enumerate(final_params)}\n",
    "        else:\n",
    "            model = self.TFQ_model(symbols)\n",
    "            qoutput = tf.ones((1, 1))*self.lower_bound_Eg\n",
    "            model.fit(x=tfqcircuit, y=qoutput, batch_size=1, epochs=self.qepochs, verbose=self.verbose)\n",
    "            energy = np.squeeze(tf.math.reduce_sum(model.predict(tfqcircuit), axis=-1))\n",
    "            final_params = [np.squeeze(k.numpy()) for k in model.trainable_variables]\n",
    "            resolver = {\"th_\"+str(ind):var  for ind,var in enumerate(final_params)}\n",
    "        return gates_index, resolver, energy\n",
    "    \n",
    "    \n",
    "    def accept_modification(self, energy):\n",
    "        return self.lowest_energy_found > energy\n",
    "    \n",
    "    \n",
    "    def optimize_and_update(self, model, circuit,variables):\n",
    "\n",
    "        #### fit continuous parameters ###\n",
    "        tfqcircuit = tfq.convert_to_tensor([circuit])\n",
    "        qoutput = tf.ones((1, 1))*self.lower_bound_Eg\n",
    "        model.fit(x=tfqcircuit, y=qoutput, batch_size=1, epochs=self.qepochs, verbose=0)\n",
    "        energy = np.squeeze(tf.math.reduce_sum(model.predict(tfqcircuit), axis=-1))\n",
    "\n",
    "        if self.accept_modification(energy):\n",
    "            self.lowest_energy_found = energy\n",
    "\n",
    "            #### if we accept the new configuration, then save the symbols in the correct order for the next iteration.\n",
    "\n",
    "            symbols, new_symbols = variables\n",
    "\n",
    "            for ind,k in enumerate(symbols):\n",
    "                self.resolver[k] = model.trainable_variables[0].numpy()[ind]\n",
    "\n",
    "            for indnew,knew in enumerate(new_symbols):\n",
    "                self.new_resolver[knew] = model.trainable_variables[0].numpy()[len(symbols)+indnew]\n",
    "\n",
    "            final_symbols = []\n",
    "            old_solver = []\n",
    "            old_added = []\n",
    "\n",
    "            final_resolver = {}\n",
    "            new_circuit = []\n",
    "            for ind, g in enumerate(self.current_circuit):\n",
    "                #### insert new block ####\n",
    "                if ind == insertion_index:\n",
    "                    for gate in block_to_insert:\n",
    "                        new_circuit.append(gate)\n",
    "                        if gate < sol.number_of_cnots:\n",
    "                            pass\n",
    "                        else:\n",
    "                            for par, gateblock in zip(range(3),sol.parametrized_unitary):\n",
    "\n",
    "                                var1 = \"New_th_\"+str(len(old_added))\n",
    "                                old_added.append(var1)\n",
    "\n",
    "                                var2 = \"th_\"+str(len(final_symbols))\n",
    "                                final_symbols.append(var2)\n",
    "                                final_resolver[var2] = self.new_resolver[var1] #\n",
    "\n",
    "                if g < self.number_of_cnots:\n",
    "                    new_circuit.append(g)\n",
    "                    pass\n",
    "                else:\n",
    "                    new_circuit.append(g)\n",
    "                    for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                        var3 = \"th_\"+str(len(old_solver))\n",
    "                        old_solver.append(var3)\n",
    "\n",
    "                        var4 = \"th_\"+str(len(final_symbols))\n",
    "                        final_symbols.append(var4)\n",
    "                        final_resolver[var4] = self.resolver[var3] \n",
    "\n",
    "            self.resolver = final_resolver\n",
    "            self.current_circuit = new_circuit\n",
    "            return new_circuit, self.resolver, energy\n",
    "        else:\n",
    "            return self.current_circuit, self.resolver, self.lower_bound_Eg\n",
    "    \n",
    "    def kill_one_unitary(self, gates_index, resolver, energy):\n",
    "        \"\"\"\n",
    "        this function takes circuit as described by gates_index (sequence of integers)\n",
    "        and returns when possible, a circuit, resolver, energy with one single-qubit unitary less.\n",
    "        \"\"\"\n",
    "        if energy == 0.:\n",
    "            energy = 10**-12\n",
    "\n",
    "        circuit_proposals=[]\n",
    "\n",
    "        for j in gates_index:\n",
    "            indexed_prop=[]\n",
    "\n",
    "            prop=cirq.Circuit()\n",
    "            checking = False\n",
    "            ko=0\n",
    "            to_pop=[]\n",
    "\n",
    "            for k in gates_index:\n",
    "                if k < self.number_of_cnots:\n",
    "                    indexed_prop.append(k)\n",
    "                    control, target = self.indexed_cnots[str(k)]\n",
    "                    prop.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "                else:\n",
    "                    if k != j:\n",
    "                        indexed_prop.append(k)\n",
    "                        qubit = self.qubits[(k-self.number_of_cnots)%self.n_qubits]\n",
    "                        for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                            new_param = \"th_\"+str(ko)\n",
    "                            ko+=1\n",
    "                            prop.append(gate(sympy.Symbol(new_param)).on(qubit))\n",
    "                    else:\n",
    "                        checking=True\n",
    "                        for i in range(3):\n",
    "                            to_pop.append(\"th_\"+str(ko))\n",
    "                            ko+=1\n",
    "            if checking is True:\n",
    "                nr = resolver.copy()\n",
    "                for p in to_pop:\n",
    "                    nr.pop(p)  \n",
    "                \n",
    "                effective_qubits = list(prop.all_qubits())\n",
    "                for k in self.qubits:\n",
    "                    if k not in effective_qubits:\n",
    "                        prop.append(cirq.I.on(k))\n",
    "                \n",
    "                tfqcircuit = tfq.convert_to_tensor([cirq.resolve_parameters(prop, nr)]) ###resolver parameters !!!\n",
    "                expval = tfq.layers.Expectation()(\n",
    "                                        tfqcircuit,\n",
    "                                        operators=tfq.convert_to_tensor([self.observable]))\n",
    "                new_energy = np.float32(np.squeeze(tf.math.reduce_sum(expval, axis=-1, keepdims=True)))\n",
    "\n",
    "                if new_energy/energy < 1.01 and new_energy < 0:\n",
    "                    ordered_resolver = {}\n",
    "                    for ind,k in enumerate(nr.values()):\n",
    "                        ordered_resolver[\"th_\"+str(ind)] = k\n",
    "                    circuit_proposals.append([indexed_prop,ordered_resolver,new_energy])\n",
    "        if len(circuit_proposals)>0:\n",
    "            favourite = np.random.choice(len(circuit_proposals))\n",
    "            short_circuit, resolver, energy = circuit_proposals[favourite]\n",
    "            return short_circuit, resolver, energy\n",
    "        else:\n",
    "            return gates_index, resolver, energy\n",
    "\n",
    "    \n",
    "    def simplify_circuit(self,indexed_circuit):\n",
    "        \"\"\"this function kills repeated unitaries and \n",
    "        CNOTS and returns a simplified indexed_circuit vector\"\"\"\n",
    "        #load circuit on each qubit\n",
    "        connections={str(q):[] for q in range(self.n_qubits)} #this saves the gates in each qubit\n",
    "        places_gates = {str(q):[] for q in range(self.n_qubits)} #this saves, for each gate on each qubit, the position in the original indexed_circuit\n",
    "\n",
    "\n",
    "        flagged = [False]*len(indexed_circuit) #to check if you have seen a cnot already, so not to append it twice to the qubit's dictionary\n",
    "\n",
    "        for q in range(self.n_qubits): #sweep over all qubits\n",
    "            for nn,idq in enumerate(indexed_circuit): #sweep over all gates in original circuit's vector\n",
    "                if idq<self.number_of_cnots: #if the gate it's a CNOT or not\n",
    "                    control, target = self.indexed_cnots[str(idq)] #give control and target qubit\n",
    "                    if q in [control, target] and not flagged[nn]: #if the qubit we are looking at is affected by this CNOT, and we haven't add this CNOT to the dictionary yet\n",
    "                        connections[str(control)].append(idq)\n",
    "                        connections[str(target)].append(idq)\n",
    "                        places_gates[str(control)].append(nn)\n",
    "                        places_gates[str(target)].append(nn)\n",
    "                        flagged[nn] = True #so you don't add the other\n",
    "                else:\n",
    "                    if idq%self.n_qubits == q: #check if the unitary is applied to the qubit we are looking at\n",
    "                        connections[str(q)].append(\"u\")\n",
    "                        places_gates[str(q)].append(nn)\n",
    "\n",
    "\n",
    "        ### now reducing the circuit\n",
    "        new_indexed_circuit = indexed_circuit.copy()\n",
    "        for q, path in connections.items(): ###sweep over qubits: path is all the gates that act this qubit during the circuit\n",
    "            for ind,gate in enumerate(path):\n",
    "                if gate == \"u\": ## IF GATE IS SINGLE QUIT UNITARY, CHECK IF THE NEXT ONES ARE ALSO UNITARIES AND KILL 'EM\n",
    "                    for k in range(len(path)-ind-1):\n",
    "                        if path[ind+k+1]==\"u\":\n",
    "                            new_indexed_circuit[places_gates[str(q)][ind+k+1]] = -1\n",
    "                        else:\n",
    "                            break\n",
    "                elif gate in range(self.number_of_cnots) and ind<len(path)-1: ### self.number_of_cnots is the maximum index of a CNOT gate for a fixed self.n_qubits.\n",
    "                    if path[ind+1]==gate and not (new_indexed_circuit[places_gates[str(q)][ind]] == -1): #check if the next gate is the same CNOT; and check if I haven't corrected the original one (otherwise you may simplify 3 CNOTs to id)\n",
    "                        others = self.indexed_cnots[str(gate)].copy()\n",
    "                        others.remove(int(q)) #the other qubit affected by the CNOT\n",
    "                        for jind, jgate in enumerate(connections[str(others[0])][:-1]): ##sweep the other qubit's gates until i find \"gate\"\n",
    "                            if jgate == gate and connections[str(others[0])][jind+1] == gate: ##i find the same gate that is repeated in both the original qubit and this one\n",
    "                                if (places_gates[str(q)][ind] == places_gates[str(others[0])][jind]) and (places_gates[str(q)][ind+1] == places_gates[str(others[0])][jind+1]): #check that positions in the indexed_circuit are the same\n",
    "                                 ###maybe I changed before, so I have repeated in the original but one was shut down..\n",
    "                                    new_indexed_circuit[places_gates[str(q)][ind]] = -1 ###just kill the repeated CNOTS\n",
    "                                    new_indexed_circuit[places_gates[str(q)][ind+1]] = -1 ###just kill the repeated CNOTS\n",
    "                                    break\n",
    "                                    \n",
    "                if gate in range(self.number_of_cnots) and ind == 0: ###if I have a CNOT just before initializing, it does nothing (if |0> initialization).\n",
    "                    others = self.indexed_cnots[str(gate)].copy()\n",
    "                    others.remove(int(q)) #the other qubit affected by the CNOT\n",
    "                    for jind, jgate in enumerate(connections[str(others[0])][:-1]): ##sweep the other qubit's gates until i find \"gate\"\n",
    "                        if jgate == gate and jind==0: ##it's also the first gate in the other qubit\n",
    "                            if (places_gates[str(q)][ind] == places_gates[str(others[0])][jind]): #check that positions in the indexed_circuit are the same\n",
    "                                new_indexed_circuit[places_gates[str(q)][ind]] = -1 ###just kill the repeated CNOTS\n",
    "                                break\n",
    "                    \n",
    "                    \n",
    "        final=[]\n",
    "        for gmarked in new_indexed_circuit:\n",
    "            if not gmarked == -1:\n",
    "                final.append(gmarked)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = Solver(qlr=0.1, qepochs=10)\n",
    "gates_index = [0] ## begin with a certain circuit\n",
    "sol.current_circuit = gates_index\n",
    "gates_index, resolver, energy= sol.run_circuit_from_index(gates_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -6\n"
     ]
    }
   ],
   "source": [
    "qubits = np.random.choice(sol.n_qubits, 2,replace = False)\n",
    "block_to_insert = sol.resolution_2cnots(qubits[0], qubits[1])\n",
    "insertion_index = np.random.choice(max(1,len(gates_index))) #gives index between \\in [0, len(gates_index) )\n",
    "\n",
    "\n",
    "circuit, variables = sol.prepare_circuit_insertion(gates_index, block_to_insert, insertion_index)\n",
    "model = sol.initialize_model_insertion(variables)\n",
    "gates_index, resolver, energy = sol.optimize_and_update(model, circuit, variables)\n",
    "print(\"1\",energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'expectation_61/circuit_learnable_parameters:0' shape=(6,) dtype=float32, numpy=\n",
       " array([-0.07990468,  0.9373264 ,  0.37687808, -0.11959718, -0.9384299 ,\n",
       "        -0.23320238], dtype=float32)>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gates_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'New_th_0': 0.002306861660245343,\n",
       " 'New_th_1': 0.004559079940641435,\n",
       " 'New_th_2': 0.0033046759284442364,\n",
       " 'New_th_3': 0.006234868544774072,\n",
       " 'New_th_4': -0.004553326224113272,\n",
       " 'New_th_5': 0.0050559956385469035}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.new_resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-155-50855cb404f9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-155-50855cb404f9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cirq.resolve_parameters(circuit,\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "cirq.resolve_parameters(circuit, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(tfq.convert_to_tensor([circuit]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1.1759347\n",
      "2 -0.9252508\n",
      "3 1.6829153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "gates_index, resolver, energy =  sol.kill_one_unitary(gates_index, resolver, energy)\n",
    "print(\"2\",energy)\n",
    "\n",
    "### now I simplify the circuit and if the length is changed I run the optimization again\n",
    "simplified_gates_index = sol.simplify_circuit(gates_index)\n",
    "if len(simplified_gates_index)<len(gates_index):\n",
    "    gates_index, resolver, energy = sol.run_circuit_from_index(simplified_gates_index)\n",
    "    print(\"3\",energy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow: auto; white-space: pre;\">(0, 0): ───Rz(-0.637π)───Rx(0.127π)───Rz(-0.409π)───@───\n",
       "                                                    │\n",
       "(0, 1): ────────────────────────────────────────────X───</pre>"
      ],
      "text/plain": [
       "(0, 0): ───Rz(-0.637π)───Rx(0.127π)───Rz(-0.409π)───@───\n",
       "                                                    │\n",
       "(0, 1): ────────────────────────────────────────────X───"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cirq.resolve_parameters(sol.give_circuit(gates_index)[0], resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.lowest_energy_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0): ───Rz(th_3)───Rx(th_4)───Rz(th_5)───X───Rz(th_6)───Rx(th_7)───Rz(th_8)───@───\n",
       "                                            │                                    │\n",
       "(0, 1): ────────────────────────────────────┼────────────────────────────────────X───\n",
       "                                            │\n",
       "(0, 2): ───Rz(th_0)───Rx(th_1)───Rz(th_2)───@────────────────────────────────────────,\n",
       " ['th_0', 'th_1', 'th_2', 'th_3', 'th_4', 'th_5', 'th_6', 'th_7', 'th_8'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = Solver(qlr=0.1, qepochs=10)\n",
    "sol.give_circuit(sol.simplify_circuit(gates_index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(3,) dtype=float32, numpy=array([-2.0010426 ,  0.39947617, -1.2855568 ], dtype=float32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sol.TFQ_model(symbols)\n",
    "qoutput = tf.ones((1, 1))*sol.lower_bound_Eg\n",
    "model.trainable_variables[0].assign(tf.convert_to_tensor(list(resolver.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Found a Pauli sum operating on qubits not found in circuit.\n\t [[node model_14/expectation_46/TfqSimulateExpectation (defined at <string>:69) ]] [Op:__inference_distributed_function_15651]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_14/expectation_46/TfqSimulateExpectation:\n IteratorGetNext (defined at <ipython-input-136-5739c50c617e>:1)\t\n model_14/expectation_46/15641 (defined at /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/expectation.py:291)\t\n model_14/expectation_46/Tile_1 (defined at /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/expectation.py:288)\t\n model_14/expectation_46/Const (defined at /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/input_checks.py:65)\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-5739c50c617e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgive_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgates_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    636\u001b[0m               *args, **kwds)\n\u001b[1;32m    637\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Found a Pauli sum operating on qubits not found in circuit.\n\t [[node model_14/expectation_46/TfqSimulateExpectation (defined at <string>:69) ]] [Op:__inference_distributed_function_15651]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_14/expectation_46/TfqSimulateExpectation:\n IteratorGetNext (defined at <ipython-input-136-5739c50c617e>:1)\t\n model_14/expectation_46/15641 (defined at /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/expectation.py:291)\t\n model_14/expectation_46/Tile_1 (defined at /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/expectation.py:288)\t\n model_14/expectation_46/Const (defined at /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/input_checks.py:65)\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "model.predict(tfq.convert_to_tensor([sol.give_circuit(gates_index)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Found a Pauli sum operating on qubits not found in circuit. [Op:TfqSimulateExpectation]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-20a4d150f605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcirq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgive_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgates_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_quantum/python/layers/circuit_executors/expectation.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, symbol_names, symbol_values, operators, initializer)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         return self._expectation_op(inputs, symbol_names, symbol_values,\n\u001b[0;32m--> 291\u001b[0;31m                                     operators)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;34m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_mode_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_mode_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m_eager_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m   \u001b[0;34m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m   \u001b[0mall_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m   \u001b[0;31m# The variables that grad_fn needs to return gradients for are the set of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36mop_wrapper_analytic\u001b[0;34m(programs, symbol_names, symbol_values, pauli_sums)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                 pauli_sums):\n\u001b[1;32m    127\u001b[0m             forward_pass_vals = analytic_op(programs, symbol_names,\n\u001b[0;32m--> 128\u001b[0;31m                                             symbol_values, pauli_sums)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_quantum/core/ops/tfq_simulate_ops.py\u001b[0m in \u001b[0;36mtfq_simulate_expectation\u001b[0;34m(programs, symbol_names, symbol_values, pauli_sums)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     return SIM_OP_MODULE.tfq_simulate_expectation(\n\u001b[0;32m---> 45\u001b[0;31m         programs, symbol_names, tf.cast(symbol_values, tf.float32), pauli_sums)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mtfq_simulate_expectation\u001b[0;34m(programs, symbol_names, symbol_values, pauli_sums, name)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Found a Pauli sum operating on qubits not found in circuit. [Op:TfqSimulateExpectation]"
     ]
    }
   ],
   "source": [
    "model(tfq.convert_to_tensor([cirq.resolve_parameters(sol.give_circuit(gates_index),resolver)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tfqcircuit, y=qoutput, batch_size=1, epochs=self.qepochs, verbose=self.verbose)\n",
    "energy = np.squeeze(tf.math.reduce_sum(model.predict(tfqcircuit), axis=-1))\n",
    "final_params = [np.squeeze(k.numpy()) for k in model.trainable_variables]\n",
    "resolver = {\"th_\"+str(ind):var  for ind,var in enumerate(final_params)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
