{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy\n",
    "import cirq\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, n_qubits=3, qlr=0.01, qepochs=100,verbose=0, g=1, J=0):\n",
    "\n",
    "        \"\"\"\"solver with n**2 possible actions: n(n-1) CNOTS + n 1-qubit unitary\"\"\"\n",
    "        self.n_qubits = n_qubits\n",
    "        self.qubits = cirq.GridQubit.rect(1, n_qubits)\n",
    "        self.lower_bound_Eg = -2*self.n_qubits\n",
    "        \n",
    "        self.qlr = qlr\n",
    "        self.qepochs=qepochs\n",
    "        self.verbose=verbose\n",
    "\n",
    "\n",
    "        self.indexed_cnots = {}\n",
    "        self.cnots_index = {}\n",
    "        count = 0\n",
    "        for control in range(self.n_qubits):\n",
    "            for target in range(self.n_qubits):\n",
    "                if control != target:\n",
    "                    self.indexed_cnots[str(count)] = [control, target]\n",
    "                    self.cnots_index[str([control,target])] = count\n",
    "                    count += 1\n",
    "        self.number_of_cnots = len(self.indexed_cnots)\n",
    "        \n",
    "        self.final_params = []\n",
    "        self.parametrized_unitary = [cirq.rz, cirq.rx, cirq.rz]\n",
    "        \n",
    "        self.observable=self.ising_obs(g=g, J=J)\n",
    "        self.resolver = {}\n",
    "        self.new_resolver = {} #this temporarly stores initialized parameters of identity resolution\n",
    "        self.lowest_energy_found = -.1\n",
    "        self.best_circuit_found = []\n",
    "        self.best_resolver_found = {}\n",
    "        \n",
    "        \n",
    "    def ising_obs(self, g=1, J=0):\n",
    "        # -  \\Gamma/2 \\sum_i Z_i - J/2 \\sum_{i} X_i X_{i+1}    (S_i = \\Sigma_i/2; ej S_z = Z/2, S_x = X/2)\n",
    "        ### analytic solution https://sci-hub.tw/https://www.sciencedirect.com/science/article/abs/pii/0003491670902708?via%3Dihub\n",
    "        observable = [-float(0.5*g)*cirq.Z.on(q) for q in self.qubits] \n",
    "        for q in range(len(self.qubits)):\n",
    "            observable.append(-float(0.5*J)*cirq.X.on(self.qubits[q])*cirq.X.on(self.qubits[(q+1)%len(self.qubits)]))\n",
    "        #### E_0 = -\\Gamma/2 \\sum_k \\Lambda_k , with \\Lambda_k = \\sqrt{ 1 + \\lambda^{2}  + 2 \\lambda \\cos(k)}; \n",
    "        ### k = -N/2, ... , 0 ,... N/2-1 if N even\n",
    "        #### k = -(N-1)/2, ... 0 , ... (N-1)/2 if N odd\n",
    "        if self.n_qubits%2 == 0:\n",
    "            val = -self.n_qubits/2\n",
    "        else:\n",
    "            val = -(self.n_qubits-1)/2\n",
    "        values_q = []\n",
    "        for k in range(2*self.n_qubits):\n",
    "            values_q.append(val)\n",
    "            val += 1/2\n",
    "        ###soething wrong here.\n",
    "        self.ground_energy = -(0.5*g)*np.sum(np.sqrt([1+(J/(2*g))**2 - (np.cos(2*np.pi*q/self.n_qubits)*(J/g)) for q in values_q]))\n",
    "        return observable\n",
    "        \n",
    "    def index_meaning(self,index):\n",
    "        if index<self.number_of_cnots:\n",
    "            print(\"cnot: \",self.indexed_cnots[str(index)])\n",
    "            return\n",
    "        else:\n",
    "            print(\"1-qubit unitary on: \",(index-self.number_of_cnots)%self.n_qubits)\n",
    "            return\n",
    "\n",
    "    def append_to_circuit(self, ind, circuit, params, new_index=False):\n",
    "        \"\"\"\n",
    "        appends to circuit the index of the gate;\n",
    "        and if one_hot_gate implies a rotation,\n",
    "        appends to params a symbol\n",
    "        \"\"\"\n",
    "        if ind < self.number_of_cnots:\n",
    "            control, target = self.indexed_cnots[str(ind)]\n",
    "            circuit.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "            return circuit, params\n",
    "        else:\n",
    "            qubit = self.qubits[(ind-self.number_of_cnots)%self.n_qubits]\n",
    "            for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                new_param = \"th_\"+str(len(params))\n",
    "                params.append(new_param)\n",
    "                circuit.append(gate(sympy.Symbol(new_param)).on(qubit))\n",
    "            return circuit, params\n",
    "        \n",
    "    def give_circuit(self, lista,one_hot=False):\n",
    "        circuit, symbols = [], []\n",
    "        for k in lista:\n",
    "            circuit, symbols = self.append_to_circuit(k,circuit,symbols)\n",
    "        circuit = cirq.Circuit(circuit)\n",
    "        return circuit, symbols\n",
    "    \n",
    "    \n",
    "    def resolution_2cnots(self, q1, q2):\n",
    "        u1 = self.number_of_cnots + q1\n",
    "        u2 = self.number_of_cnots + q2\n",
    "        cnot = self.cnots_index[str([q1,q2])]\n",
    "        return [cnot, u1, u2, cnot]\n",
    "    \n",
    "    def resolution_1qubit(self, q):\n",
    "        u1 = self.number_of_cnots + q\n",
    "        return [u1]\n",
    "        \n",
    "\n",
    "    def dressed_cnot(self,q1,q2):\n",
    "        u1 = self.number_of_cnots + q1\n",
    "        u2 = self.number_of_cnots + q2\n",
    "        cnot = self.cnots_index[str([q1,q2])]\n",
    "        u3 = self.number_of_cnots + q1\n",
    "        u4 = self.number_of_cnots + q2\n",
    "        return [u1,u2,cnot,u3,u4]\n",
    "    \n",
    "    def dressed_ansatz(self, layers=1):\n",
    "        c=[]\n",
    "        for layer in range(layers):\n",
    "            qubits = list(range(self.n_qubits))\n",
    "            qdeph = qubits[layers:]\n",
    "            for q in qubits[:layers]:\n",
    "                qdeph.append(q)\n",
    "            for ind1, ind2 in zip(qubits,qdeph):\n",
    "                for k in self.dressed_cnot(ind1,ind2):\n",
    "                    c.append(k)\n",
    "        return c\n",
    "\n",
    "\n",
    "    def prepare_circuit_insertion(self,gates_index, block_to_insert, index_insertion):\n",
    "        \"\"\"gates_index is a vector with integer entries, each one describing a gate\n",
    "            block_to_insert is block of unitaries to insert at index insertion\n",
    "        \"\"\"\n",
    "        circuit = cirq.Circuit()\n",
    "        idx_circuit=[]\n",
    "        symbols = []\n",
    "        new_symbols = []\n",
    "        new_resolver = {}\n",
    "\n",
    "        for ind, g in enumerate(gates_index):\n",
    "            #### insert new block ####\n",
    "            if ind == insertion_index:\n",
    "                for gate in block_to_insert:\n",
    "                    idx_circuit.append(gate)\n",
    "                    if gate < self.number_of_cnots:\n",
    "                        control, target = self.indexed_cnots[str(gate)]\n",
    "                        circuit.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "                    else:\n",
    "                        qubit = self.qubits[(gate-self.number_of_cnots)%self.n_qubits]\n",
    "                        for par, gateblack in zip(range(3),self.parametrized_unitary):\n",
    "                            new_symbol = \"New_th_\"+str(len(new_symbols))\n",
    "                            new_symbols.append(new_symbol)\n",
    "                            new_resolver[new_symbol] = np.random.uniform(-.1,.1) #rotation around epsilon... we can do it better afterwards\n",
    "                            circuit.append(gateblack(sympy.Symbol(new_symbol)).on(qubit))\n",
    "            if g < self.number_of_cnots:\n",
    "                idx_circuit.append(g)\n",
    "                control, target = self.indexed_cnots[str(g)]\n",
    "                circuit.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "            else:\n",
    "                idx_circuit.append(g)\n",
    "                qubit = self.qubits[(ind-self.number_of_cnots)%self.n_qubits]\n",
    "                for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                    new_symbol = \"th_\"+str(len(symbols))\n",
    "                    symbols.append(new_symbol)\n",
    "                    circuit.append(gate(sympy.Symbol(new_symbol)).on(qubit))\n",
    "                    if not new_symbol in self.resolver.keys(): #this is in case it's the first time. Careful when deleting !\n",
    "                        self.resolver[new_symbol] = np.random.uniform(-np.pi, np.pi)\n",
    "\n",
    "        ### add identity for TFQ tocompute correctily expected value####\n",
    "        effective_qubits = list(circuit.all_qubits())\n",
    "        for k in self.qubits:\n",
    "            if k not in effective_qubits:\n",
    "                circuit.append(cirq.I.on(k))\n",
    "        self.new_resolver = new_resolver\n",
    "        #self.current_circuit = idx_circuit ### store the new indexed circuit (whose resolver is obtained from both self.new_resolver and self.resolver)\n",
    "        variables = [symbols, new_symbols]\n",
    "        return circuit, variables#, idx_circuit\n",
    "    \n",
    "    \n",
    "    \n",
    "    def TFQ_model(self, symbols):\n",
    "        circuit_input = tf.keras.Input(shape=(), dtype=tf.string)\n",
    "        output = tfq.layers.Expectation()(\n",
    "                circuit_input,\n",
    "                symbol_names=symbols,\n",
    "                operators=tfq.convert_to_tensor([self.observable]),\n",
    "                initializer=tf.keras.initializers.RandomNormal()) #we may change this!!!\n",
    "\n",
    "        model = tf.keras.Model(inputs=circuit_input, outputs=output)\n",
    "        adam = tf.keras.optimizers.Adam(learning_rate=self.qlr)\n",
    "        model.compile(optimizer=adam, loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def initialize_model_insertion(self, variables):\n",
    "        ### initialize model with parameters from previous model (describer by variables[0]) --> values in self.resolver\n",
    "        ###(for the already-optimized ones), and close to identity for the block added, described by variables[1], whose values are in self.new_resolver\n",
    "\n",
    "        symbols, new_symbols = variables\n",
    "        circuit_symbols = []\n",
    "        init_params = []\n",
    "        for j in symbols:\n",
    "            circuit_symbols.append(j)\n",
    "            init_params.append(self.resolver[str(j)])#+ np.random.uniform(-.01,.01)) if you want to perturbate previous parameters..\n",
    "        for k in new_symbols:\n",
    "            circuit_symbols.append(k)\n",
    "            init_params.append(self.new_resolver[str(k)])\n",
    "\n",
    "        model = self.TFQ_model(circuit_symbols)\n",
    "        model.trainable_variables[0].assign(tf.convert_to_tensor(init_params)) #initialize parameters of model (continuous parameters of uniraries)\n",
    "        #with the corresponding values\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cirq_friendly_observable(self, obs):\n",
    "        PAULI_BASIS = {\n",
    "            'I': np.eye(2),\n",
    "            'X': np.array([[0., 1.], [1., 0.]]),\n",
    "            'Y': np.array([[0., -1j], [1j, 0.]]),\n",
    "            'Z': np.diag([1., -1]),\n",
    "        }\n",
    "\n",
    "        pauli3 = cirq.linalg.operator_spaces.kron_bases(PAULI_BASIS, repeat=self.n_qubits)\n",
    "        decomp = cirq.linalg.operator_spaces.expand_matrix_in_orthogonal_basis(obs, pauli3)\n",
    "\n",
    "        PAULI_BASIS_CIRQ = {\n",
    "            'I': cirq.X,\n",
    "            'X': cirq.X,\n",
    "            'Y': cirq.Y,\n",
    "            'Z': cirq.Z,\n",
    "        }\n",
    "\n",
    "        unt = []\n",
    "        for term in decomp.items():\n",
    "            gate_name = term[0]\n",
    "            coeff = term[1]\n",
    "            s = 0\n",
    "            ot = float(coeff)\n",
    "            for qpos, single_gate in enumerate(gate_name):\n",
    "                if single_gate == \"I\":\n",
    "                    ot *= PAULI_BASIS_CIRQ[single_gate](self.qubits[qpos])*PAULI_BASIS_CIRQ[single_gate](self.qubits[qpos])\n",
    "                else:\n",
    "                    ot *= PAULI_BASIS_CIRQ[single_gate](self.qubits[qpos])\n",
    "            if s < 3:\n",
    "                unt.append(ot)\n",
    "        return unt\n",
    "\n",
    "\n",
    "    def run_circuit_from_index(self, gates_index):\n",
    "        \"\"\"\n",
    "        takes as input vector with actions described as integer\n",
    "        and outputsthe energy of that circuit (w.r.t self.observable)\n",
    "        \"\"\"\n",
    "        ### create a vector with the gates on the corresponding qubit(s)\n",
    "        circuit, symbols = self.give_circuit(gates_index)\n",
    "        \n",
    "        ### this is because each qubit should be \"activated\" in TFQ to do the optimization (if the observable has support on this qubit as well and you don't add I then error)\n",
    "        effective_qubits = list(circuit.all_qubits())\n",
    "        for k in self.qubits:\n",
    "            if k not in effective_qubits:\n",
    "                circuit.append(cirq.I.on(k))\n",
    "\n",
    "        tfqcircuit = tfq.convert_to_tensor([circuit])\n",
    "        if len(symbols) == 0:\n",
    "            expval = tfq.layers.Expectation()(\n",
    "                                            tfqcircuit,\n",
    "                                            operators=tfq.convert_to_tensor([self.observable]))\n",
    "            energy = np.float32(np.squeeze(tf.math.reduce_sum(expval, axis=-1, keepdims=True)))\n",
    "            final_params = []\n",
    "            resolver = {\"th_\"+str(ind):var  for ind,var in enumerate(final_params)}\n",
    "        else:\n",
    "            model = self.TFQ_model(symbols)\n",
    "            qoutput = tf.ones((1, 1))*self.lower_bound_Eg\n",
    "            model.fit(x=tfqcircuit, y=qoutput, batch_size=1, epochs=self.qepochs, verbose=self.verbose)\n",
    "            energy = np.squeeze(tf.math.reduce_sum(model.predict(tfqcircuit), axis=-1))\n",
    "            final_params = model.trainable_variables[0].numpy()\n",
    "            resolver = {\"th_\"+str(ind):var  for ind,var in enumerate(final_params)}\n",
    "        return gates_index, resolver, energy\n",
    "    \n",
    "    \n",
    "    def accept_modification(self, energy):\n",
    "        return energy < self.lowest_energy_found# or np.random.random() >.9# accept a bad one with some probability a la metropolis (maybe use \\delta E)\n",
    "    \n",
    "    \n",
    "    def optimize_and_update(self, model, circuit,variables,insertion_index_loaded):\n",
    "        #### fit continuous parameters ###\n",
    "        \n",
    "        k=0\n",
    "        for ind,gh in enumerate(list(circuit.all_operations())):\n",
    "            if gh.gate == cirq.I:\n",
    "                k+=1\n",
    "        if ind == k-1:\n",
    "            return self.current_circuit, self.resolver, self.lowest_energy_found\n",
    "            \n",
    "        tfqcircuit = tfq.convert_to_tensor([circuit])\n",
    "        qoutput = tf.ones((1, 1))*self.lower_bound_Eg\n",
    "        model.fit(x=tfqcircuit, y=qoutput, batch_size=1, epochs=self.qepochs, verbose=0)\n",
    "        energy = np.squeeze(tf.math.reduce_sum(model.predict(tfqcircuit), axis=-1))\n",
    "\n",
    "        if self.accept_modification(energy):\n",
    "            self.lowest_energy_found = energy\n",
    "            \n",
    "            #### if we accept the new configuration, then we update the resolver merging both symbols and new_symbols into self.resolver\n",
    "            symbols, new_symbols = variables\n",
    "\n",
    "            for ind,k in enumerate(symbols):\n",
    "                self.resolver[k] = model.trainable_variables[0].numpy()[ind]\n",
    "\n",
    "            for indnew,knew in enumerate(new_symbols):\n",
    "                self.new_resolver[knew] = model.trainable_variables[0].numpy()[len(symbols)+indnew]\n",
    "\n",
    "            final_symbols = []\n",
    "            old_solver = []\n",
    "            old_added = []\n",
    "\n",
    "            final_resolver = {}\n",
    "            new_circuit = []\n",
    "            for ind, g in enumerate(self.current_circuit): #self.current_circuit is associated with symbols and current self.resolver\n",
    "                \n",
    "                #### insert new block ####\n",
    "                if ind == insertion_index_loaded:\n",
    "                    for gate in block_to_insert:\n",
    "                        new_circuit.append(gate)\n",
    "                        if gate < sol.number_of_cnots:\n",
    "                            pass\n",
    "                        else:\n",
    "                            for par, gateblock in zip(range(3),sol.parametrized_unitary):\n",
    "\n",
    "                                var1 = \"New_th_\"+str(len(old_added))\n",
    "                                old_added.append(var1)\n",
    "\n",
    "                                var2 = \"th_\"+str(len(final_symbols))\n",
    "                                final_symbols.append(var2)\n",
    "                                final_resolver[var2] = self.new_resolver[var1] #\n",
    "\n",
    "                if g < self.number_of_cnots:\n",
    "                    new_circuit.append(g)\n",
    "                    pass\n",
    "                else:\n",
    "                    new_circuit.append(g)\n",
    "                    for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                        var3 = \"th_\"+str(len(old_solver))\n",
    "                        old_solver.append(var3)\n",
    "\n",
    "                        var4 = \"th_\"+str(len(final_symbols))\n",
    "                        final_symbols.append(var4)\n",
    "                        final_resolver[var4] = self.resolver[var3] \n",
    "\n",
    "            self.resolver = final_resolver\n",
    "            self.current_circuit = new_circuit #### now the current circuit is the better one! :\n",
    "            self.best_circuit_found = new_circuit\n",
    "            self.best_resolver_found = resolver\n",
    "            return new_circuit, self.resolver, energy\n",
    "        else:\n",
    "            return self.current_circuit, self.resolver, self.lowest_energy_found\n",
    "    \n",
    "    def kill_one_unitary(self, gates_index, resolver, energy):\n",
    "        \"\"\"\n",
    "        this function takes circuit as described by gates_index (sequence of integers)\n",
    "        and returns when possible, a circuit, resolver, energy with one single-qubit unitary less.\n",
    "        \"\"\"\n",
    "        if energy == 0.:\n",
    "            energy = 10**-12\n",
    "\n",
    "        circuit_proposals=[] #storing all good candidates.\n",
    "        \n",
    "        for j in gates_index:\n",
    "            indexed_prop=[]\n",
    "\n",
    "            prop=cirq.Circuit()\n",
    "            checking = False\n",
    "            ko=0\n",
    "            to_pop=[]\n",
    "\n",
    "            for k in gates_index:\n",
    "                if k < self.number_of_cnots:\n",
    "                    indexed_prop.append(k)\n",
    "                    control, target = self.indexed_cnots[str(k)]\n",
    "                    prop.append(cirq.CNOT.on(self.qubits[control], self.qubits[target]))\n",
    "                else:\n",
    "                    if k != j:\n",
    "                        indexed_prop.append(k)\n",
    "                        qubit = self.qubits[(k-self.number_of_cnots)%self.n_qubits]\n",
    "                        for par, gate in zip(range(3),self.parametrized_unitary):\n",
    "                            new_param = \"th_\"+str(ko)\n",
    "                            ko+=1\n",
    "                            prop.append(gate(sympy.Symbol(new_param)).on(qubit))\n",
    "                    else:\n",
    "                        checking=True\n",
    "                        for i in range(3):\n",
    "                            to_pop.append(\"th_\"+str(ko))\n",
    "                            ko+=1\n",
    "            if checking is True:\n",
    "                nr = resolver.copy()\n",
    "                for p in to_pop:\n",
    "                    nr.pop(p)  \n",
    "                \n",
    "                effective_qubits = list(prop.all_qubits())\n",
    "                for k in self.qubits:\n",
    "                    if k not in effective_qubits:\n",
    "                        prop.append(cirq.I.on(k))\n",
    "                \n",
    "                tfqcircuit = tfq.convert_to_tensor([cirq.resolve_parameters(prop, nr)]) ###resolver parameters !!!\n",
    "                expval = tfq.layers.Expectation()(\n",
    "                                        tfqcircuit,\n",
    "                                        operators=tfq.convert_to_tensor([self.observable]))\n",
    "                new_energy = np.float32(np.squeeze(tf.math.reduce_sum(expval, axis=-1, keepdims=True)))\n",
    "\n",
    "                if self.accept_modification(new_energy):\n",
    "                    ordered_resolver = {}\n",
    "                    for ind,k in enumerate(nr.values()):\n",
    "                        ordered_resolver[\"th_\"+str(ind)] = k\n",
    "                    circuit_proposals.append([indexed_prop,ordered_resolver,new_energy])\n",
    "        if len(circuit_proposals)>0:\n",
    "            favourite = np.random.choice(len(circuit_proposals))\n",
    "            short_circuit, resolver, energy = circuit_proposals[favourite]\n",
    "            self.current_circuit = short_circuit\n",
    "            self.resolver = resolver\n",
    "            \n",
    "            ### save shortest..\n",
    "            self.best_resolver_found = resolver\n",
    "            self.best_circuit_found = short_circuit\n",
    "            simplified=True\n",
    "            return short_circuit, resolver, energy, simplified\n",
    "        else:\n",
    "            simplified=False\n",
    "            return gates_index, resolver, energy, simplified\n",
    "\n",
    "    \n",
    "    def simplify_circuit(self,indexed_circuit):\n",
    "        \"\"\"this function kills repeated unitaries and \n",
    "        CNOTS and returns a simplified indexed_circuit vector\"\"\"\n",
    "        #load circuit on each qubit\n",
    "        connections={str(q):[] for q in range(self.n_qubits)} #this saves the gates in each qubit\n",
    "        places_gates = {str(q):[] for q in range(self.n_qubits)} #this saves, for each gate on each qubit, the position in the original indexed_circuit\n",
    "\n",
    "\n",
    "        flagged = [False]*len(indexed_circuit) #to check if you have seen a cnot already, so not to append it twice to the qubit's dictionary\n",
    "\n",
    "        for q in range(self.n_qubits): #sweep over all qubits\n",
    "            for nn,idq in enumerate(indexed_circuit): #sweep over all gates in original circuit's vector\n",
    "                if idq<self.number_of_cnots: #if the gate it's a CNOT or not\n",
    "                    control, target = self.indexed_cnots[str(idq)] #give control and target qubit\n",
    "                    if q in [control, target] and not flagged[nn]: #if the qubit we are looking at is affected by this CNOT, and we haven't add this CNOT to the dictionary yet\n",
    "                        connections[str(control)].append(idq)\n",
    "                        connections[str(target)].append(idq)\n",
    "                        places_gates[str(control)].append(nn)\n",
    "                        places_gates[str(target)].append(nn)\n",
    "                        flagged[nn] = True #so you don't add the other\n",
    "                else:\n",
    "                    if idq%self.n_qubits == q: #check if the unitary is applied to the qubit we are looking at\n",
    "                        connections[str(q)].append(\"u\")\n",
    "                        places_gates[str(q)].append(nn)\n",
    "\n",
    "\n",
    "        ### now reducing the circuit\n",
    "        new_indexed_circuit = indexed_circuit.copy()\n",
    "        for q, path in connections.items(): ###sweep over qubits: path is all the gates that act this qubit during the circuit\n",
    "            for ind,gate in enumerate(path):\n",
    "                if gate == \"u\": ## IF GATE IS SINGLE QUIT UNITARY, CHECK IF THE NEXT ONES ARE ALSO UNITARIES AND KILL 'EM\n",
    "                    for k in range(len(path)-ind-1):\n",
    "                        if path[ind+k+1]==\"u\":\n",
    "                            new_indexed_circuit[places_gates[str(q)][ind+k+1]] = -1\n",
    "                        else:\n",
    "                            break\n",
    "                elif gate in range(self.number_of_cnots) and ind<len(path)-1: ### self.number_of_cnots is the maximum index of a CNOT gate for a fixed self.n_qubits.\n",
    "                    if path[ind+1]==gate and not (new_indexed_circuit[places_gates[str(q)][ind]] == -1): #check if the next gate is the same CNOT; and check if I haven't corrected the original one (otherwise you may simplify 3 CNOTs to id)\n",
    "                        others = self.indexed_cnots[str(gate)].copy()\n",
    "                        others.remove(int(q)) #the other qubit affected by the CNOT\n",
    "                        for jind, jgate in enumerate(connections[str(others[0])][:-1]): ##sweep the other qubit's gates until i find \"gate\"\n",
    "                            if jgate == gate and connections[str(others[0])][jind+1] == gate: ##i find the same gate that is repeated in both the original qubit and this one\n",
    "                                if (places_gates[str(q)][ind] == places_gates[str(others[0])][jind]) and (places_gates[str(q)][ind+1] == places_gates[str(others[0])][jind+1]): #check that positions in the indexed_circuit are the same\n",
    "                                 ###maybe I changed before, so I have repeated in the original but one was shut down..\n",
    "                                    new_indexed_circuit[places_gates[str(q)][ind]] = -1 ###just kill the repeated CNOTS\n",
    "                                    new_indexed_circuit[places_gates[str(q)][ind+1]] = -1 ###just kill the repeated CNOTS\n",
    "                                    break\n",
    "                                    \n",
    "                if gate in range(self.number_of_cnots) and ind == 0: ###if I have a CNOT just before initializing, it does nothing (if |0> initialization).\n",
    "                    others = self.indexed_cnots[str(gate)].copy()\n",
    "                    others.remove(int(q)) #the other qubit affected by the CNOT\n",
    "                    for jind, jgate in enumerate(connections[str(others[0])][:-1]): ##sweep the other qubit's gates until i find \"gate\"\n",
    "                        if jgate == gate and jind==0: ##it's also the first gate in the other qubit\n",
    "                            if (places_gates[str(q)][ind] == places_gates[str(others[0])][jind]): #check that positions in the indexed_circuit are the same\n",
    "                                new_indexed_circuit[places_gates[str(q)][ind]] = -1 ###just kill the repeated CNOTS\n",
    "                                break\n",
    "                    \n",
    "        #### remove the marked indices ###### \n",
    "        #### remove the marked indices ######            \n",
    "        \n",
    "        final=[]\n",
    "        for gmarked in new_indexed_circuit:\n",
    "            if not gmarked == -1:\n",
    "                final.append(gmarked)\n",
    "        return final\n",
    "    \n",
    "    def count_number_cnots(self, gates_index):\n",
    "        c=0\n",
    "        for k in gates_index:\n",
    "            if k<self.number_of_cnots:\n",
    "                c+=1\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = Solver(3, g=1, J=.5, qlr=0.01)\n",
    "#sol.observable = [cirq.Z.on(k)*cirq.Z.on(k)/sol.n_qubits for k in sol.qubits]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitt = [0, sol.number_of_cnots, sol.number_of_cnots+1,sol.number_of_cnots+2,0]\n",
    "circuitcirq, symbols = sol.give_circuit(circuitt)\n",
    "effective_qubits = list(sol.give_circuit(circuitt)[0].all_qubits())\n",
    "for k in sol.qubits:\n",
    "    if k not in effective_qubits:\n",
    "        circuitcirq.append(cirq.I.on(k))\n",
    "        \n",
    "circuit_input = tf.keras.Input(shape=(), dtype=tf.string)\n",
    "output = tfq.layers.Expectation()(\n",
    "        tfq.convert_to_tensor([circuitcirq]),\n",
    "        symbol_names=symbols,\n",
    "        operators=tfq.convert_to_tensor([sol.observable]),\n",
    "        initializer=tf.keras.initializers.RandomNormal(mean=np.pi,stddev=np.pi)) #we may change this!!!\n",
    "\n",
    "model = tf.keras.Model(inputs=circuit_input, outputs=output)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=.01)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a3591df6b6a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtfqcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcircuitcirq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfqcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 721\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    722\u001b[0m     return predict_loop(\n\u001b[1;32m    723\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[0;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[1;32m   1293\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[1;32m   1294\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[0;32m-> 1295\u001b[0;31m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[1;32m   1296\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "tfqcircuit = tfq.convert_to_tensor([circuitcirq])\n",
    "energy = np.squeeze(tf.math.reduce_sum(model.predict(tfqcircuit), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "Epoch 1/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.5675\n",
      "Epoch 2/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 3/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 4/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 5/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 6/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 7/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 8/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 9/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 10/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 11/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 12/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 13/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 14/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 15/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 16/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 17/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 18/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 19/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 20/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 21/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 22/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 23/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 24/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 25/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 26/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 27/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 28/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 29/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 30/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 31/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 32/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 33/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 34/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 35/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 36/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 37/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 38/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 39/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 40/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 41/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 42/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 43/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 44/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 45/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 46/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 47/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 48/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 49/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 50/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 51/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 52/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 53/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 54/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 55/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 56/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 57/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 58/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 59/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 60/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 61/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 62/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 63/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 64/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 65/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 66/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.5675\n",
      "Epoch 67/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 68/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 69/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 70/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 71/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 72/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 73/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 74/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 75/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 76/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 77/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 78/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 79/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 80/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 81/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 82/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 83/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 84/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 85/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 86/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 87/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 88/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 89/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 90/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 91/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 92/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 93/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 94/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 95/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 96/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 97/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 98/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 99/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 100/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 101/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 102/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 103/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 104/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 105/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 106/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 107/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 108/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 109/120\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5675\n",
      "Epoch 110/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 111/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 112/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 113/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 114/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 115/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 116/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 117/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 118/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 119/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n",
      "Epoch 120/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.5675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73921b0550>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfqcircuit = tfq.convert_to_tensor([circuitcirq])\n",
    "\n",
    "qoutput = tf.ones((1, 1))*-4.\n",
    "model.fit(x=tfqcircuit, y=qoutput, batch_size=1, epochs=120, verbose=1, steps_per_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Could not compute output Tensor(\"expectation_10/IdentityN:0\", shape=(1, 6), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-de9312217164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfqcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not compute output '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0moutput_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Could not compute output Tensor(\"expectation_10/IdentityN:0\", shape=(1, 6), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model(tfqcircuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = np.squeeze(tf.math.reduce_sum(, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
